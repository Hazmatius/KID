# KID
KID is an effort by me ([Alex Baranski](https://www.linkedin.com/in/alex-baranski-082100a1/)) to construct a robotic arm. I think that one of the major limits of a system is that systems ability to interact with its environment through its sensory and motor apparatuses, and that simulation of an environment for training a system is [1] prone to leaving out important but hard to simulate dynamics that exist in the real world and [2] is less cool. I looked around for a robotic arm I could buy, but there's pretty much nothing in my price range that's any better than a simple claw, which I'm not interested in. So, I decided to just build my own! This is one of several things I'm juggling so new posts are infrequent, but at the end I'll make a single comprehensive tutorial with links to materials and digital resources used in the construction of the "final" iteration.
Because I'm making this from scratch, I have to learn a lot as I go, which is pretty fun. Because I'm also funding it myself, it also has to be cheap. And because I'd like to be able to iterate quickly, rapid manufacturing with limited tools is non-negotiable. I think making the whole arm low-cost is an interesting creative limitation, and I hope will make robotics more accessible than it currently is.

I have some details about the hardware at [this website](https://sites.google.com/s/1cxzKrNBqjHTFoiHB7bzBj2pTloyNXd0s/p/1--FoMWqyCzP7gzcQ5LMKvzVR4WBZFQIs/edit)

## Dataset
If I knew anything about physics, and the hand design I was using had actual joints instead of some fishing line pulling on plastic connected by duct-tape, I could probably just write a kinematics model. But I haven't taken physics in almost five years, and the hand is in fact just some plastic connected by duct-tape getting pulled around by some fishing line. So instead, I've decided to train a neural network to model the physics of the hand.
If you know anything about neural networks, you know they need data. So, I took two of the fingers off of KID (I only  wanted to have to deal with control of a single finger for the time being) and set it up on a stand in the corner of a room with white walls and relatively uniform lighting. Then I wrote some code to generate random (but continuous, the randomness was in the derivative of the commands, so KID wouldn't get jolted around. I found it helped generate smoother motions) and simultaneously take pictures of the finger. This is an example of what's called motor-babbling. Motor-babbling is when you randomly move around and just see how your sensors change. It's not a terribly sophisticated way to learn about your body, but it IS very easy to implement, so that's what I did. I collected about 10,000 data points, saved it as a folder of images with each image named by the motor commands that were sent during that time-frame, as well as a timestamp to help order the frames.

Then I wrote a little neural network in PyTorch with a dataloader that could deliver the image of the finger, motor commands, and timestamp for a single instant in time, as well as the previous and following instants. Basically, each datapoint looks like the image below. For a given timestamp t, there is a sensor state vector st that corresponds to the image taken at that instant, as well as an action vector at that corresponds to the motor commands sent at that instant. We also get the previous state and action and the following state and action, marked as (st-1, at-1) and (st+1, at+1), respectively. The dataloader at this point has already sorted through everything and knows how to just grab these things irrespective the timestamp, so it can assemble a batch of random time points.
